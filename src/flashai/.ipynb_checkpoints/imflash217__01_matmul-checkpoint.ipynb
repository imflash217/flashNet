{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_00_exports import *\n",
    "import operator\n",
    "\n",
    "def test(a, b, cmp, cname=None):\n",
    "    if cname is None:\n",
    "        cname = cmp.__name__\n",
    "    assert cmp(a, b), f\"{cname}:\\n{a}\\n{b}\"\n",
    "    \n",
    "def test_eq(a,b):\n",
    "    test(a, b, operator.eq, \"==\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\ntest\ntest1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-325ec235cb2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-317bbe1d7aea>\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-317bbe1d7aea>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\ntest\ntest1"
     ]
    }
   ],
   "source": [
    "test_eq(TEST, \"test1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "import gzip\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "from fastai import datasets\n",
    "\n",
    "MNIST_URL = \"http://deeplearning.net/data/mnist/mnist.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/potter217/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = datasets.download_data(url=MNIST_URL, ext=\".gz\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(filename=path, mode=\"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(file=f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., ..., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([50000, 784]) torch.Size([50000]) tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))\n",
    "n, c = x_train.shape\n",
    "\n",
    "print(type(x_train[0]), x_train.shape, y_train.shape, y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n == y_train.shape[0] == 50000\n",
    "test_eq(c, 28*28)            ### checking the size of image\n",
    "test_eq(y_train.min(), 0)\n",
    "test_eq(y_train.max(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### setting parameters for matplotlib color scheme\n",
    "mpl.rcParams[\"image.cmap\"] = \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = x_train[0]\n",
    "img.view(28, 28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.view(28, 28))      ### avoid using this method; instead use the above one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5cb6734320>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X=img.view(28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Python model\n",
    "\n",
    "```\n",
    "y = (a * x) + b\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights = torch.rand(784, 10)\n",
    "weights = torch.rand(x_train.shape[1], (y_train.max()+1))\n",
    "bias = torch.zeros(y_train.max()+1)\n",
    "\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `matmul()` version #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    result = torch.zeros(a_rows, b_cols)\n",
    "    \n",
    "    for i in range(a_rows):\n",
    "        for j in range(b_cols):\n",
    "            for k in range(a_cols):    ### or range(b_rows); since a_cols == b_rows\n",
    "                result[i, j] += a[i, k] * b[k, j]                \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 784])\n"
     ]
    }
   ],
   "source": [
    "m1 = x_train[:12]\n",
    "print(m1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.99 s ± 326 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y1_hat = matmul(m1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_v1 = 2.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 10])\n"
     ]
    }
   ],
   "source": [
    "print(y1_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is very slow. \n",
    "### Lets speed it up by $50,000$ times.....!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1., 22, 3])\n",
    "b = torch.Tensor([20., 10, 60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 22.,  3.])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20., 10., 60.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21., 32., 63.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a<b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor([[1., 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Forbenius Norm\n",
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `matmul()` improved version #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    \n",
    "    result = torch.zeros(a_rows, b_cols)\n",
    "    for i in range(a_rows):\n",
    "        for j in range(b_cols):\n",
    "            result[i, j] = (a[i,:] * b[:,j]).sum()  ### NOTE: any trailing \",:\" during indexing can be removed\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9693, 0.9890, 0.1097,  ..., 0.1751, 0.7761, 0.3786],\n",
       "        [0.8336, 0.2123, 0.7028,  ..., 0.6217, 0.3784, 0.1071],\n",
       "        [0.8765, 0.4144, 0.9597,  ..., 0.3919, 0.8120, 0.6929],\n",
       "        ...,\n",
       "        [0.7545, 0.6650, 0.5470,  ..., 0.7674, 0.3968, 0.4206],\n",
       "        [0.3597, 0.6276, 0.2634,  ..., 0.8109, 0.6353, 0.3845],\n",
       "        [0.2962, 0.5482, 0.4339,  ..., 0.0170, 0.4489, 0.2497]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.26 ms ± 471 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y1_v2_hat = matmul(m1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_v2 = 4.26*(10**(-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701.8779342723005"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### factor_improvement\n",
    "time_v1/time_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "### test whether the results from two methods are same or not\n",
    "### as its difficult to accurately achieve the same numbers due to floating-point operation\n",
    "### we will create a function to test whether two tensor (of same shape) are \n",
    "### APPROXIMATELY EQUAL withing some tolerance\n",
    "\n",
    "def near(a, b):\n",
    "    return torch.allclose(input=a, other=b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a, b):\n",
    "    return test(a=a, b=b, cmp=near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(y1_hat, y1_v2_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "```\n",
    "The term broadcasting was first in Numpy.\n",
    "Broadcasting :\n",
    "    \"\n",
    "    Broadcasting describes how numpy treats arrays with different shapes during arithmetic operations.\n",
    "    Generally, the smaller array is BROADCAST across the alrger array so that they have compatible shapes.\n",
    "    Broadcasting provides a way of VECTORIZING array operations, so that looping occurs in C & not Python.\n",
    "    It does this without useless copies of data and usually leads to efficient algorithmic implementations.\n",
    "    It also allows users to write less code and hence lesser error.\n",
    "    \"\n",
    "When operating on arrays/tensors numpy/pytorch compare their shapes element-wise.\n",
    "\n",
    "Rules of broadcasting:\n",
    "    1. Two dimensions are compatible when \n",
    "        * they are equal\n",
    "        * one of them is 1, in which case that dimension is broadcasted    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1., 22.,  3.]), torch.Size([3]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1., 22.,  3.]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_ = a.unsqueeze(dim=0)\n",
    "a_, a_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.],\n",
       "         [22.],\n",
       "         [ 3.]]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a__ = a.unsqueeze(dim=1)\n",
    "a__, a__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.],\n",
       "          [22.],\n",
       "          [ 3.]]]), torch.Size([1, 3, 1]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a___ = a_.unsqueeze(dim=2)\n",
    "a___, a___.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1., 22.,  3.]]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None], a[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None] is a.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None] == a.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 22.,  3.],\n",
       "        [ 1., 22.,  3.],\n",
       "        [ 1., 22.,  3.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1., 22.,  3.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., 24.,  6.],\n",
       "        [ 5., 27.,  9.],\n",
       "        [ 8., 30., 12.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., 24.,  6.],\n",
       "        [ 5., 27.,  9.],\n",
       "        [ 8., 30., 12.]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2., 24.,  6.],\n",
       "        [ 5., 27.,  9.],\n",
       "        [ 8., 30., 12.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + a.expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = a.expand_as(m)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 22.0\n",
       " 3.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       " 6.0\n",
       " 7.0\n",
       " 8.0\n",
       " 9.0\n",
       "[torch.FloatStorage of size 9]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, a.unsqueeze(dim=0).shape, a.unsqueeze(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, a[None, :].shape, a[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, torch.Size([1, 3]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None].shape == a[None, :].shape, a[None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, torch.Size([3, 1]))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..., None].shape == a[:, None].shape, a[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 22.,  3.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.],\n",
       "        [22.],\n",
       "        [ 3.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..., None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `matmul()` much improved version #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    a_rows, a_cols = a.shape\n",
    "    b_rows, b_cols = b.shape\n",
    "    \n",
    "    assert a_cols == b_rows\n",
    "    \n",
    "    result = torch.zeros(a_rows, b_cols)\n",
    "    \n",
    "    for i in range(a_rows):\n",
    "        ### broadcasting each row of a into b and then summing the ouput across rows i.e. sum all column values for each row\n",
    "        ### result[i] = (a[..., None] * b).sum(dim=0)\n",
    "        result[i] = (a[i].unsqueeze(-1) * b).sum(dim=0)\n",
    "        \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "933 µs ± 61 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 matmul(m1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_v3 = 930 * (10**-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3215.0537634408606"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### fraction improvement\n",
    "time_v1/time_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(y1_hat, matmul(m1, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein summation `einsum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    return torch.einsum(\"ik,kj->ij\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 225 µs, sys: 3 µs, total: 228 µs\n",
      "Wall time: 237 µs\n"
     ]
    }
   ],
   "source": [
    "%time y1_v4_hat = matmul(m1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_v4 = 228*(10**-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13114.0350877193"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_v1/time_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(y1_hat, y1_v4_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch ops `matmul()` / `@`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a, b):\n",
    "    return a.matmul(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.5 µs ± 4.63 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 y1_v5_hat = matmul(m1, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_v5 = 18.5*(10**-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161621.62162162163"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_v1/time_v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## That is more than 100K time faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted imflash217__01_matmul.ipynb to exp/nb_01_matmul.py\r\n",
      "Converted imflash217__01_matmul.ipynb to exp/nb_01_matmul.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook_to_script.py imflash217__01_matmul.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[00m\r\n",
      "├── \u001b[01;34mexp\u001b[00m\r\n",
      "│   ├── nb_00_exports.py\r\n",
      "│   ├── nb_01_matmul.py\r\n",
      "│   └── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "│       └── nb_00_exports.cpython-36.pyc\r\n",
      "├── imflash217__00_exports.ipynb\r\n",
      "├── imflash217__01_matmul.ipynb\r\n",
      "├── notebook_to_script.py\r\n",
      "└── run_notebook.py\r\n",
      "\r\n",
      "2 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;238m───────┬────────────────────────────────────────────────────────────────────────\u001b[0m\r\n",
      "       \u001b[38;5;238m│ \u001b[0mFile: \u001b[1mexp/nb_01_matmul.py\u001b[0m\r\n",
      "\u001b[38;5;238m───────┼────────────────────────────────────────────────────────────────────────\u001b[0m\r\n",
      "\u001b[38;5;238m   1\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m   2\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m#########################################\u001b[0m\r\n",
      "\u001b[38;5;238m   3\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m##### This file was autogenerated. ######\u001b[0m\r\n",
      "\u001b[38;5;238m   4\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m######## DO NOT EDIT this file. #########\u001b[0m\r\n",
      "\u001b[38;5;238m   5\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m#########################################\u001b[0m\r\n",
      "\u001b[38;5;238m   6\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m## file to edit: dev_nb/imflash217__01_matmul.ipynb ####\u001b[0m\r\n",
      "\u001b[38;5;238m   7\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m   8\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;249;38;114mfrom\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mexp\u001b[0m\u001b[38;2;248;248;242m.\u001b[0m\u001b[38;2;248;248;242mnb_00_exports\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;249;38;114mimport\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;190;132;255m*\u001b[0m\r\n",
      "\u001b[38;5;238m   9\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;249;38;114mimport\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242moperator\u001b[0m\r\n",
      "\u001b[38;5;238m  10\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m  11\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;166;226;46mdef\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;166;226;46mtest\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mb\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mcmp\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mcname\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;190;132;255mNone\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\u001b[38;2;248;248;242m:\u001b[0m\r\n",
      "\u001b[38;5;238m  12\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m    \u001b[0m\u001b[38;2;249;38;114mif\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mcname\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;249;38;114mis\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;190;132;255mNone\u001b[0m\u001b[38;2;248;248;242m:\u001b[0m\r\n",
      "\u001b[38;5;238m  13\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m        \u001b[0m\u001b[38;2;248;248;242mcname\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;102;217;239mcmp\u001b[0m\u001b[38;2;248;248;242m.\u001b[0m\u001b[38;2;248;248;242m__name__\u001b[0m\r\n",
      "\u001b[38;5;238m  14\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m    \u001b[0m\u001b[38;2;249;38;114massert\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;102;217;239mcmp\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;248;248;242ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mb\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\u001b[38;2;248;248;242m, \u001b[0m\u001b[38;2;102;217;239mf\u001b[0m\u001b[38;2;230;219;116m\"\u001b[0m\u001b[38;2;248;248;242m{\u001b[0m\u001b[38;2;248;248;242mcname\u001b[0m\u001b[38;2;248;248;242m}\u001b[0m\u001b[38;2;230;219;116m:\u001b[0m\u001b[38;2;190;132;255m\\n\u001b[0m\u001b[38;2;248;248;242m{\u001b[0m\u001b[38;2;248;248;242ma\u001b[0m\u001b[38;2;248;248;242m}\u001b[0m\u001b[38;2;190;132;255m\\n\u001b[0m\u001b[38;2;248;248;242m{\u001b[0m\u001b[38;2;248;248;242mb\u001b[0m\u001b[38;2;248;248;242m}\u001b[0m\u001b[38;2;230;219;116m\"\u001b[0m\r\n",
      "\u001b[38;5;238m  15\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m  16\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;166;226;46mdef\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;166;226;46mtest_eq\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;253;151;31mb\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\u001b[38;2;248;248;242m:\u001b[0m\r\n",
      "\u001b[38;5;238m  17\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m    \u001b[0m\u001b[38;2;248;248;242mtest\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;248;248;242ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mb\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242moperator\u001b[0m\u001b[38;2;248;248;242m.\u001b[0m\u001b[38;2;248;248;242meq\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;230;219;116m\"\u001b[0m\u001b[38;2;230;219;116m==\u001b[0m\u001b[38;2;230;219;116m\"\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\r\n",
      "\u001b[38;5;238m  18\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m  19\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m## test whether the results from two methods are same or not\u001b[0m\r\n",
      "\u001b[38;5;238m  20\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m## as its difficult to accurately achieve the same numbers due to floa\u001b[0m\r\n",
      "\u001b[38;5;238m    \u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94mting-point operation\u001b[0m\r\n",
      "\u001b[38;5;238m  21\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m## we will create a function to test whether two tensor (of same shape\u001b[0m\r\n",
      "\u001b[38;5;238m    \u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m) are\u001b[0m\r\n",
      "\u001b[38;5;238m  22\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;117;113;94m#\u001b[0m\u001b[38;2;117;113;94m## APPROXIMATELY EQUAL withing some tolerance\u001b[0m\r\n",
      "\u001b[38;5;238m  23\u001b[0m   \u001b[38;5;238m│\u001b[0m \r\n",
      "\u001b[38;5;238m  24\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;166;226;46mdef\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;166;226;46mnear\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mb\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\u001b[38;2;248;248;242m:\u001b[0m\r\n",
      "\u001b[38;5;238m  25\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m    \u001b[0m\u001b[38;2;249;38;114mreturn\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mtorch\u001b[0m\u001b[38;2;248;248;242m.\u001b[0m\u001b[38;2;248;248;242mallclose\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31minput\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mother\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242mb\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mrtol\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;190;132;255m1e-3\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31matol\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;190;132;255m1e-5\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\r\n",
      "\u001b[38;5;238m  26\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;166;226;46mdef\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;166;226;46mtest_near\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mb\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\u001b[38;2;248;248;242m:\u001b[0m\r\n",
      "\u001b[38;5;238m  27\u001b[0m   \u001b[38;5;238m│\u001b[0m \u001b[38;2;248;248;242m    \u001b[0m\u001b[38;2;249;38;114mreturn\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;248;248;242mtest\u001b[0m\u001b[38;2;248;248;242m(\u001b[0m\u001b[38;2;253;151;31ma\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242ma\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mb\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242mb\u001b[0m\u001b[38;2;248;248;242m,\u001b[0m\u001b[38;2;248;248;242m \u001b[0m\u001b[38;2;253;151;31mcmp\u001b[0m\u001b[38;2;249;38;114m=\u001b[0m\u001b[38;2;248;248;242mnear\u001b[0m\u001b[38;2;248;248;242m)\u001b[0m\r\n",
      "\u001b[38;5;238m───────┴────────────────────────────────────────────────────────────────────────\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!bat exp/nb_01_matmul.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
