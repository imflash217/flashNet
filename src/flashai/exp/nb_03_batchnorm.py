
##########################################
###### This file was autogenerated. ######
######### DO NOT EDIT this file. #########
##########################################
### file to edit: dev_nb/imflash217__03_batchnorm.ipynb ####

from exp.nb_03_cuda_cnn_hooks_init import *


def init_cnn_(module, func):
    if isinstance(module, torch.nn.Conv2d):
        func(module.weight, a=0.1)                      ### "func" is the init function like kaiming_normal, kaiming_uniform etc
        if getattr(module, "bias", None) is not None:
            module.bias.data.zero_()
    for layer in module.children():
        init_cnn_(layer, func)

def init_cnn(module, uniform=False):
    func = init.kaiming_uniform_ if uniform else init.kaiming_normal_
    init_cnn_(module, func)

def get_learn_run(data, nfs, lr, layer, cbs=None, opt_func=None, uniform=False, **kwargs):
    model = get_cnn_model(data, nfs, layer, **kwargs)
    init_cnn(model, uniform=uniform)
    return get_runner(model, data, lr=lr, cbs=cbs, opt_func=opt_func)



def conv_layer(ni, nf, ks, stride=2, bn=True, **kwargs):
    layers = [torch.nn.Conv2d(ni, nf, ks, stride=stride, padding=ks//2, bias=not bn),
              GeneralReLU(**kwargs)]
    if bn:
        layers.append(torch.nn.BatchNorm2d(nf, eps=1e-5, momentum=0.1))
    return torch.nn.Sequential(*layers)
